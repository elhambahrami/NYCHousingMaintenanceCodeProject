{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Housing DataSet Cleaning\n",
    "\n",
    "Benny Cohen\n",
    "\n",
    "10/26/2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Housing Maintenance Code Violations found at https://data.cityofnewyork.us/Housing-Development/Housing-Maintenance-Code-Violations/wvxf-dwi5 describes several housing violations found in NY and provides details including where the incident was, (broken down by boro, and address), how severe it was (broken down into 3 classes, A,B,C where A is least severe and C the most severe)\n",
    "\n",
    "In this notebook we will clean the data:\n",
    "We need to...\n",
    "\n",
    "1. Filter for the rows we need\n",
    "2. deleting duplicate rows\n",
    "3. changing datatypes,\n",
    "4. Deal with missing data \n",
    "\n",
    "We then save the file to a csv for analysis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Setup, Thoughts about Our Data, and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://data.cityofnewyork.us/resource/wvxf-dwi5.csv?$limit=50000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 50000 rows and 40 columns \n"
     ]
    }
   ],
   "source": [
    "rows, columns = df.shape\n",
    "print('There are {:d} rows and {:d} columns '.format(rows,columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>violationid</th>\n",
       "      <th>buildingid</th>\n",
       "      <th>registrationid</th>\n",
       "      <th>boroid</th>\n",
       "      <th>boro</th>\n",
       "      <th>housenumber</th>\n",
       "      <th>lowhousenumber</th>\n",
       "      <th>highhousenumber</th>\n",
       "      <th>streetname</th>\n",
       "      <th>streetcode</th>\n",
       "      <th>zip</th>\n",
       "      <th>apartment</th>\n",
       "      <th>story</th>\n",
       "      <th>block</th>\n",
       "      <th>lot</th>\n",
       "      <th>class</th>\n",
       "      <th>inspectiondate</th>\n",
       "      <th>approveddate</th>\n",
       "      <th>originalcertifybydate</th>\n",
       "      <th>originalcorrectbydate</th>\n",
       "      <th>newcertifybydate</th>\n",
       "      <th>newcorrectbydate</th>\n",
       "      <th>certifieddate</th>\n",
       "      <th>ordernumber</th>\n",
       "      <th>novid</th>\n",
       "      <th>novdescription</th>\n",
       "      <th>novissueddate</th>\n",
       "      <th>currentstatusid</th>\n",
       "      <th>currentstatus</th>\n",
       "      <th>currentstatusdate</th>\n",
       "      <th>novtype</th>\n",
       "      <th>violationstatus</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>communityboard</th>\n",
       "      <th>councildistrict</th>\n",
       "      <th>censustract</th>\n",
       "      <th>bin</th>\n",
       "      <th>bbl</th>\n",
       "      <th>nta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000009</td>\n",
       "      <td>265980</td>\n",
       "      <td>301467</td>\n",
       "      <td>3</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>355</td>\n",
       "      <td>355</td>\n",
       "      <td>355</td>\n",
       "      <td>EAST 48 STREET</td>\n",
       "      <td>36930</td>\n",
       "      <td>11203.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4674</td>\n",
       "      <td>64</td>\n",
       "      <td>B</td>\n",
       "      <td>2013-10-08T00:00:00.000</td>\n",
       "      <td>2013-10-09T00:00:00.000</td>\n",
       "      <td>2013-11-28T00:00:00.000</td>\n",
       "      <td>2013-11-14T00:00:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>508</td>\n",
       "      <td>4705852</td>\n",
       "      <td>SECTION 27-2005 ADM CODE  REPAIR THE BROKEN OR...</td>\n",
       "      <td>2013-10-10T00:00:00.000</td>\n",
       "      <td>19</td>\n",
       "      <td>VIOLATION CLOSED</td>\n",
       "      <td>2015-03-31T00:00:00.000</td>\n",
       "      <td>Original</td>\n",
       "      <td>Close</td>\n",
       "      <td>40.653217</td>\n",
       "      <td>-73.932480</td>\n",
       "      <td>17.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>870.0</td>\n",
       "      <td>3102071.0</td>\n",
       "      <td>3.046740e+09</td>\n",
       "      <td>East Flatbush-Farragut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000011</td>\n",
       "      <td>73852</td>\n",
       "      <td>226626</td>\n",
       "      <td>2</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>1123</td>\n",
       "      <td>1123</td>\n",
       "      <td>1123</td>\n",
       "      <td>EAST TREMONT AVENUE</td>\n",
       "      <td>29620</td>\n",
       "      <td>10460.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4004</td>\n",
       "      <td>9</td>\n",
       "      <td>B</td>\n",
       "      <td>2013-10-09T00:00:00.000</td>\n",
       "      <td>2013-10-15T00:00:00.000</td>\n",
       "      <td>2013-12-04T00:00:00.000</td>\n",
       "      <td>2013-11-20T00:00:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>686</td>\n",
       "      <td>4708486</td>\n",
       "      <td>SECTION 27-2040 ADM CODE  PROVIDE ADEQUATE LIG...</td>\n",
       "      <td>2013-10-16T00:00:00.000</td>\n",
       "      <td>19</td>\n",
       "      <td>VIOLATION CLOSED</td>\n",
       "      <td>2015-09-15T00:00:00.000</td>\n",
       "      <td>Original</td>\n",
       "      <td>Close</td>\n",
       "      <td>40.839954</td>\n",
       "      <td>-73.876599</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>2042428.0</td>\n",
       "      <td>2.040040e+09</td>\n",
       "      <td>East Tremont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000012</td>\n",
       "      <td>80102</td>\n",
       "      <td>211704</td>\n",
       "      <td>2</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>751</td>\n",
       "      <td>751</td>\n",
       "      <td>751</td>\n",
       "      <td>GERARD AVENUE</td>\n",
       "      <td>35020</td>\n",
       "      <td>10451.0</td>\n",
       "      <td>3L</td>\n",
       "      <td>3</td>\n",
       "      <td>2482</td>\n",
       "      <td>30</td>\n",
       "      <td>B</td>\n",
       "      <td>2013-10-08T00:00:00.000</td>\n",
       "      <td>2013-10-10T00:00:00.000</td>\n",
       "      <td>2013-11-29T00:00:00.000</td>\n",
       "      <td>2013-11-15T00:00:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>501</td>\n",
       "      <td>4706454</td>\n",
       "      <td>SECTION 27-2005 ADM CODE  PROPERLY REPAIR THE ...</td>\n",
       "      <td>2013-10-11T00:00:00.000</td>\n",
       "      <td>19</td>\n",
       "      <td>VIOLATION CLOSED</td>\n",
       "      <td>2014-10-17T00:00:00.000</td>\n",
       "      <td>Original</td>\n",
       "      <td>Close</td>\n",
       "      <td>40.824692</td>\n",
       "      <td>-73.926605</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2002971.0</td>\n",
       "      <td>2.024820e+09</td>\n",
       "      <td>West Concourse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000014</td>\n",
       "      <td>268639</td>\n",
       "      <td>350942</td>\n",
       "      <td>3</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>EAST 52 STREET</td>\n",
       "      <td>37080</td>\n",
       "      <td>11203.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yards / Courts</td>\n",
       "      <td>4605</td>\n",
       "      <td>19</td>\n",
       "      <td>B</td>\n",
       "      <td>2013-10-09T00:00:00.000</td>\n",
       "      <td>2013-10-10T00:00:00.000</td>\n",
       "      <td>2013-11-29T00:00:00.000</td>\n",
       "      <td>2013-11-15T00:00:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>686</td>\n",
       "      <td>4706684</td>\n",
       "      <td>SECTION 27-2040 ADM CODE  PROVIDE ADEQUATE LIG...</td>\n",
       "      <td>2013-10-11T00:00:00.000</td>\n",
       "      <td>19</td>\n",
       "      <td>VIOLATION CLOSED</td>\n",
       "      <td>2016-08-16T00:00:00.000</td>\n",
       "      <td>Original</td>\n",
       "      <td>Close</td>\n",
       "      <td>40.659731</td>\n",
       "      <td>-73.929295</td>\n",
       "      <td>17.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>878.0</td>\n",
       "      <td>3099672.0</td>\n",
       "      <td>3.046050e+09</td>\n",
       "      <td>Prospect Lefferts Gardens-Wingate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000017</td>\n",
       "      <td>268167</td>\n",
       "      <td>300713</td>\n",
       "      <td>3</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>EAST 52 STREET</td>\n",
       "      <td>37080</td>\n",
       "      <td>11203.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yards / Courts</td>\n",
       "      <td>4621</td>\n",
       "      <td>21</td>\n",
       "      <td>B</td>\n",
       "      <td>2013-10-09T00:00:00.000</td>\n",
       "      <td>2013-10-10T00:00:00.000</td>\n",
       "      <td>2013-11-29T00:00:00.000</td>\n",
       "      <td>2013-11-15T00:00:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>686</td>\n",
       "      <td>4706680</td>\n",
       "      <td>SECTION 27-2040 ADM CODE  PROVIDE ADEQUATE LIG...</td>\n",
       "      <td>2013-10-11T00:00:00.000</td>\n",
       "      <td>19</td>\n",
       "      <td>VIOLATION CLOSED</td>\n",
       "      <td>2014-09-30T00:00:00.000</td>\n",
       "      <td>Original</td>\n",
       "      <td>Close</td>\n",
       "      <td>40.657615</td>\n",
       "      <td>-73.929067</td>\n",
       "      <td>17.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>878.0</td>\n",
       "      <td>3100214.0</td>\n",
       "      <td>3.046210e+09</td>\n",
       "      <td>Prospect Lefferts Gardens-Wingate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   violationid  buildingid  registrationid  boroid      boro housenumber  \\\n",
       "0     10000009      265980          301467       3  BROOKLYN         355   \n",
       "1     10000011       73852          226626       2     BRONX        1123   \n",
       "2     10000012       80102          211704       2     BRONX         751   \n",
       "3     10000014      268639          350942       3  BROOKLYN          54   \n",
       "4     10000017      268167          300713       3  BROOKLYN         146   \n",
       "\n",
       "  lowhousenumber highhousenumber           streetname  streetcode      zip  \\\n",
       "0            355             355       EAST 48 STREET       36930  11203.0   \n",
       "1           1123            1123  EAST TREMONT AVENUE       29620  10460.0   \n",
       "2            751             751        GERARD AVENUE       35020  10451.0   \n",
       "3             54              54       EAST 52 STREET       37080  11203.0   \n",
       "4            146             146       EAST 52 STREET       37080  11203.0   \n",
       "\n",
       "  apartment           story  block  lot class           inspectiondate  \\\n",
       "0       NaN               2   4674   64     B  2013-10-08T00:00:00.000   \n",
       "1       NaN             NaN   4004    9     B  2013-10-09T00:00:00.000   \n",
       "2        3L               3   2482   30     B  2013-10-08T00:00:00.000   \n",
       "3       NaN  Yards / Courts   4605   19     B  2013-10-09T00:00:00.000   \n",
       "4       NaN  Yards / Courts   4621   21     B  2013-10-09T00:00:00.000   \n",
       "\n",
       "              approveddate    originalcertifybydate    originalcorrectbydate  \\\n",
       "0  2013-10-09T00:00:00.000  2013-11-28T00:00:00.000  2013-11-14T00:00:00.000   \n",
       "1  2013-10-15T00:00:00.000  2013-12-04T00:00:00.000  2013-11-20T00:00:00.000   \n",
       "2  2013-10-10T00:00:00.000  2013-11-29T00:00:00.000  2013-11-15T00:00:00.000   \n",
       "3  2013-10-10T00:00:00.000  2013-11-29T00:00:00.000  2013-11-15T00:00:00.000   \n",
       "4  2013-10-10T00:00:00.000  2013-11-29T00:00:00.000  2013-11-15T00:00:00.000   \n",
       "\n",
       "  newcertifybydate newcorrectbydate certifieddate  ordernumber    novid  \\\n",
       "0              NaN              NaN           NaN          508  4705852   \n",
       "1              NaN              NaN           NaN          686  4708486   \n",
       "2              NaN              NaN           NaN          501  4706454   \n",
       "3              NaN              NaN           NaN          686  4706684   \n",
       "4              NaN              NaN           NaN          686  4706680   \n",
       "\n",
       "                                      novdescription            novissueddate  \\\n",
       "0  SECTION 27-2005 ADM CODE  REPAIR THE BROKEN OR...  2013-10-10T00:00:00.000   \n",
       "1  SECTION 27-2040 ADM CODE  PROVIDE ADEQUATE LIG...  2013-10-16T00:00:00.000   \n",
       "2  SECTION 27-2005 ADM CODE  PROPERLY REPAIR THE ...  2013-10-11T00:00:00.000   \n",
       "3  SECTION 27-2040 ADM CODE  PROVIDE ADEQUATE LIG...  2013-10-11T00:00:00.000   \n",
       "4  SECTION 27-2040 ADM CODE  PROVIDE ADEQUATE LIG...  2013-10-11T00:00:00.000   \n",
       "\n",
       "   currentstatusid     currentstatus        currentstatusdate   novtype  \\\n",
       "0               19  VIOLATION CLOSED  2015-03-31T00:00:00.000  Original   \n",
       "1               19  VIOLATION CLOSED  2015-09-15T00:00:00.000  Original   \n",
       "2               19  VIOLATION CLOSED  2014-10-17T00:00:00.000  Original   \n",
       "3               19  VIOLATION CLOSED  2016-08-16T00:00:00.000  Original   \n",
       "4               19  VIOLATION CLOSED  2014-09-30T00:00:00.000  Original   \n",
       "\n",
       "  violationstatus   latitude  longitude  communityboard  councildistrict  \\\n",
       "0           Close  40.653217 -73.932480            17.0             41.0   \n",
       "1           Close  40.839954 -73.876599             6.0             15.0   \n",
       "2           Close  40.824692 -73.926605             4.0              8.0   \n",
       "3           Close  40.659731 -73.929295            17.0             41.0   \n",
       "4           Close  40.657615 -73.929067            17.0             41.0   \n",
       "\n",
       "   censustract        bin           bbl                                nta  \n",
       "0        870.0  3102071.0  3.046740e+09             East Flatbush-Farragut  \n",
       "1        220.0  2042428.0  2.040040e+09                       East Tremont  \n",
       "2         63.0  2002971.0  2.024820e+09                     West Concourse  \n",
       "3        878.0  3099672.0  3.046050e+09  Prospect Lefferts Gardens-Wingate  \n",
       "4        878.0  3100214.0  3.046210e+09  Prospect Lefferts Gardens-Wingate  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 50)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see several noteworthy columns that we want to keep. Let's filter for them now to make the rest of our analysis easier. \n",
    "Columns we want...\n",
    "1. violationid - unique identifier for incident. \n",
    "    A.In order to use this field we need to validate that...    \n",
    "        a.Each id truly is unique\n",
    "        b.There is only one id per incident\n",
    "        \n",
    "2. buildingid - unique identifier for building\n",
    "\n",
    "    A. We can see from this whether there are buildings with multiple incidents\n",
    "    \n",
    "    \n",
    "3. boro - This tells us which boro an incident took place in\n",
    "\n",
    "\n",
    "4. Zip - This tells us the zip code an incident took place in. \n",
    "\n",
    "    A. This field and burrow will help us find geographic trends in incidents\n",
    "    \n",
    "    B. We can use the zip field to verify that the boro field is correct\n",
    "    \n",
    "    \n",
    "5. InspectionDate - This tells us when an incident was opened.\n",
    "\n",
    "\n",
    "6. CertifiedDate - The date an incident was Corrected\n",
    "\n",
    "\n",
    "7. OriginalCorrectByDate - The day that an incident must be resolved by. \n",
    "\n",
    "\n",
    "8. NewCorrectByDate - If a postponment is granted this field will contain the date that the incident must be resolved by\n",
    "\n",
    "\n",
    "9. NOVDescription - Describes the violation\n",
    "\n",
    "\n",
    "10. Class - Tells how severe a violation is. A is most severe, B is medium, and C is low. \n",
    "\n",
    "\n",
    "11. CurrentStatus - The current status of the inspection (ie - OPEN, CLOSED...)\n",
    "\n",
    "\n",
    "12. CurrentStatusDate - The date when the status was updated to its current state\n",
    "\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..\\config\\columns.txt') as file:\n",
    "    columns = [line.rstrip().rstrip('\\n') for line in file]\n",
    "filteredData = df[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's use the info method to see the columns count and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 13 columns):\n",
      "violationid              50000 non-null int64\n",
      "buildingid               50000 non-null int64\n",
      "boro                     50000 non-null object\n",
      "zip                      49999 non-null float64\n",
      "inspectiondate           50000 non-null object\n",
      "certifieddate            8889 non-null object\n",
      "originalcorrectbydate    49444 non-null object\n",
      "newcorrectbydate         503 non-null object\n",
      "novdescription           50000 non-null object\n",
      "class                    50000 non-null object\n",
      "currentstatus            50000 non-null object\n",
      "currentstatusdate        50000 non-null object\n",
      "currentstatusdate        50000 non-null object\n",
      "dtypes: float64(1), int64(2), object(10)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "filteredData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make notes about things we need to correct. \n",
    "\n",
    "1. Missing data: We note that we had 50000 rows and see that since count ignores nulls that most of the columns contain all the info. Some don't though. Zip code is missing one row. Also Certified date is missing a lot of rows. It might be of interest to see if this column overlaps with currentstatusdate and we therefore can get rid of it. Correct by date is missing many rows simply because there weren't that many postponments granted. We might want to filter these into their own file to look at. \n",
    "\n",
    "2. Datatypes: Date columns are going to need to be changed to datetime. We actually have no 'numeric' data because all of our numeric types are ids so there is no point in doing a df.describe to see numeric info.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10080611    1\n",
       "10076248    1\n",
       "10106887    1\n",
       "10093767    1\n",
       "10047498    1\n",
       "Name: violationid, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filteredData.violationid.value_counts().sort_values(ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the highest cound for an id is 1, confirming that ids are unique. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The harder thing to check is do incidents get repeated under multiple ids.... First let's see if we have any duplicate incidents since that's easy... There are 2 ways to do this. We can use the drop duplicates function or we can merge the dataframes on the unique attributes. The first is most definetly faster but the second let's us explore the data more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 25)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined = pd.merge(filteredData,filteredData, on = ['violationid'], how = 'inner')\n",
    "joined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So when we join on the id column we get all the rows as we expected... since that is unique as we already showed Now let's join without the id column. We should get the same output if there is no duplicate data. If there is duplicate data we are going to get extra rows since each row would map to a row on something more than itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The column label 'currentstatusdate' is not unique.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-32455c963c4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mjoined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilteredData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilteredData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilteredData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'inner'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     59\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                          validate=validate)\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    549\u001b[0m         (self.left_join_keys,\n\u001b[0;32m    550\u001b[0m          \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m          self.join_names) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    855\u001b[0m                             right_keys.append(\n\u001b[0;32m    856\u001b[0m                                 right._get_label_or_level_values(\n\u001b[1;32m--> 857\u001b[1;33m                                     rk, stacklevel=stacklevel))\n\u001b[0m\u001b[0;32m    858\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis, stacklevel)\u001b[0m\n\u001b[0;32m   1399\u001b[0m                              .format(key=key,\n\u001b[0;32m   1400\u001b[0m                                      \u001b[0mlabel_axis_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel_axis_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1401\u001b[1;33m                                      multi_message=multi_message))\n\u001b[0m\u001b[0;32m   1402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1403\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The column label 'currentstatusdate' is not unique."
     ]
    }
   ],
   "source": [
    "joined = pd.merge(filteredData,filteredData, on = list(filteredData.columns)[1:], how = 'inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sameviolation = joined[joined['violationid_x'] != joined['violationid_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sameviolation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 122 rows seem to contain duplicate data... Maybe let's look at them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sameviolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One sample row\n",
    "df[df['violationid'] == 10005692]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['violationid'] == 10005758]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are these really duplicates? Maybe something is unique about them? Maybe there is a field missing from the data? Maybe it's a collection problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(sameviolation['boro'].unique(), sameviolation['boro'].value_counts())\n",
    "plt.title(\"Incidents per boro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's unclear, but we can drop them since we have enough data anyways..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredData = filteredData.set_index('violationid').sort_index() #might as well if we are treating these as ids...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredData = filteredData.drop(sameviolation.violationid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay... Part 1 is done... now let's see if incidents are repeated... Let's show the alternate method...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredData.duplicated() #No duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredData.duplicated(subset = ['buildingid', 'boro', 'zip', 'inspectiondate', 'certifieddate',\n",
    "       'originalcorrectbydate', 'novdescription', 'class',\n",
    "       ]).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are duplicates... Now let's find them to see what they look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = filteredData[filteredData.duplicated(subset = ['buildingid', 'boro', 'zip', 'inspectiondate', 'certifieddate',\n",
    "       'originalcorrectbydate', 'novdescription', 'class',\n",
    "       ], keep = False)]\n",
    "dups.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't really what we were expecting to see. We see the same violation listed 2x with different statuses. It could also just be that these were seperate violations just given the same nov description. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are in good 'shape' (pun intended) though because few such rows exist. \n",
    "\n",
    "There may in fact be multiple entries for the same incident but because we are taking a small subset of the data we don't have to deal with this problem as we have just shown. Let's just get rid of them since there are only a few"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredData = filteredData.drop(dups.violationid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correcting DataTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we need to do is convert the date columns to dates and zip to an int. The strings are encoded as categorical data properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredData['currentstatusdate'] = pd.to_datetime(filteredData['currentstatusdate'])\n",
    "filteredData['inspectiondate'] = pd.to_datetime(filteredData['inspectiondate'])\n",
    "filteredData['originalcorrectbydate'] = pd.to_datetime(filteredData['originalcorrectbydate'])\n",
    "filteredData['newcorrectbydate'] = pd.to_datetime(filteredData['newcorrectbydate'])\n",
    "filteredData['currentstatusdate '] = pd.to_datetime(filteredData['currentstatusdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredData.inspectiondate.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that they it is now a datetime (That is a datetime type). \n",
    "The last thing I want to adress are nulls. Let's see what columns have nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = filteredData.isnull().any()\n",
    "nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredData[filteredData['zip'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip looks like a data entry problem. We can leave it since the other data is usefull. The same is true of the originalcorrectbydate and newcorrectbydate fields. We simply can exclude them directly when we do the analysis. \n",
    "The newcorrectbydate is null when there are no postponments given to rectify the date. Those we can also leave since we are going to filter them to a file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reopened = filteredData[~filteredData.newcorrectbydate.isnull()]\n",
    "clean = filteredData[filteredData.newcorrectbydate.isnull()]\n",
    "\n",
    "clean.to_csv(\"../data/clean.csv\")\n",
    "reopened.to_csv(\"../data/reopened.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
